{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas version: 2.0.3\n",
      "matplotlib version: 3.7.2\n",
      "NumPy version: 1.23.5\n",
      "SciPy version: 1.10.1\n",
      "IPython version: 8.20.0\n",
      "scikit-learn version: 1.2.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version: {}\".format(sys.version))\n",
    "import pandas as pd\n",
    "print(\"pandas version: {}\".format(pd.__version__))\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"matplotlib version: {}\".format(matplotlib.__version__))\n",
    "import numpy as np\n",
    "print(\"NumPy version: {}\".format(np.__version__))\n",
    "import scipy as sp\n",
    "print(\"SciPy version: {}\".format(sp.__version__))\n",
    "import IPython\n",
    "print(\"IPython version: {}\".format(IPython.__version__))\n",
    "import sklearn\n",
    "print(\"scikit-learn version: {}\".format(sklearn.__version__))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mglearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosted regression trees (gradient boosting machines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Regression Trees (GBRT) – Simplified Explanation:\n",
    "\n",
    "Gradient Boosted Regression Trees (GBRT) is a machine learning technique used for both **regression** and **classification** tasks. Here’s how it works in simpler terms:\n",
    "\n",
    "1. **Ensemble Learning**: GBRT is an ensemble method, which means it combines multiple models (called **decision trees**) to create a stronger model. Each individual tree is weak on its own, but when combined, they make powerful predictions.\n",
    "\n",
    "2. **Serial Training**: Unlike Random Forests, which build trees independently and randomly, GBRT builds each tree one at a time in a **series**. Each new tree focuses on correcting the mistakes of the previous trees.\n",
    "\n",
    "3. **Weak Learners**: GBRT uses **shallow trees**, meaning trees with a limited depth (usually 1 to 5 layers). These trees are simple and are known as \"weak learners\" because each one can only handle part of the data well.\n",
    "\n",
    "4. **Improvement Step-by-Step**: The idea is to build one weak tree at a time and gradually **improve** the model's performance. Each tree tries to \"fix\" where the previous tree was wrong. Over time, as more trees are added, the model becomes more accurate.\n",
    "\n",
    "5. **Memory Efficient and Fast**: Because GBRT trees are shallow, the model is smaller and faster at making predictions compared to deeper decision trees.\n",
    "\n",
    "6. **Learning Rate**: GBRT uses a **learning rate** to control how strongly each new tree corrects the previous tree's mistakes. A **higher learning rate** means stronger corrections but may lead to overfitting (the model becomes too complex). A **lower learning rate** means smaller steps toward improving the model, but more trees are needed.\n",
    "\n",
    "7. **Tuning Parameters**:\n",
    "   - **n_estimators**: The number of trees in the model. More trees generally make the model better, but also more complex.\n",
    "   - **max_depth**: How deep each tree is allowed to be. Shallow trees (low depth) are used to keep the model simple.\n",
    "   - **learning_rate**: Controls how much each tree impacts the final model. A lower learning rate means more trees are needed but helps avoid overfitting.\n",
    "\n",
    "### Why GBRT Is Popular:\n",
    "- **Accuracy**: When tuned properly, GBRT can be **more accurate** than other models like Random Forests.\n",
    "- **Common in Competitions**: GBRT is often the go-to model in machine learning competitions and is widely used in industry.\n",
    "\n",
    "### Example:\n",
    "Here’s a typical usage of `GradientBoostingClassifier` (GBRT for classification) on the **Breast Cancer dataset**:\n",
    "- The model builds **100 trees**, each with a **maximum depth of 3**.\n",
    "- It uses a **learning rate of 0.1** to gradually improve the accuracy of predictions. \n",
    "\n",
    "GBRT can outperform other models if the parameters (like the number of trees and learning rate) are set correctly, making it a powerful tool in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split( cancer.data, cancer.target, random_state=0)\n",
    "\n",
    "gbrt = GradientBoostingClassifier(random_state=0)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the training set accuracy is 100%, we are likely to be overfitting. To reduce overfit‐\n",
    "ting, we could either apply stronger pre-pruning by limiting the maximum depth or\n",
    "lower the learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.991\n",
      "Accuracy on test set: 0.972\n"
     ]
    }
   ],
   "source": [
    "gbrt = GradientBoostingClassifier(random_state=0, max_depth=1)\n",
    "gbrt.fit(X_train, y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.988\n",
      "Accuracy on test set: 0.958\n"
     ]
    }
   ],
   "source": [
    "gbrt = GradientBoostingClassifier(random_state=0, learning_rate=0.01)\n",
    "gbrt.fit(X_train, y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both methods of decreasing the model complexity reduced the training set accuracy,\n",
    "as expected. In this case, lowering the maximum depth of the trees provided a signifi‐\n",
    "cant improvement of the model, while lowering the learning rate only increased the\n",
    "generalization performance slightly.\n",
    "As for the other decision tree–based models, we can again visualize the feature\n",
    "importances to get more insight into our model (Figure 2-35). As we used 100 trees, it\n",
    "is impractical to inspect them all, even if they are all of depth 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (30), usually from a call to set_ticks, does not match the number of labels (4).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature4\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Replace with actual names\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Call the function to plot feature importances\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m plot_feature_importances_cancer(gbrt)\n",
      "Cell \u001b[1;32mIn[30], line 8\u001b[0m, in \u001b[0;36mplot_feature_importances_cancer\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      6\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Number of features in the dataset\u001b[39;00m\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mbarh(\u001b[38;5;28mrange\u001b[39m(n_features), model\u001b[38;5;241m.\u001b[39mfeature_importances_, align\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m plt\u001b[38;5;241m.\u001b[39myticks(np\u001b[38;5;241m.\u001b[39marange(n_features), feature_names)  \u001b[38;5;66;03m# Replace 'feature_names' with your actual feature names\u001b[39;00m\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature Importance\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\faris\\anaconda3\\Lib\\site-packages\\matplotlib\\pyplot.py:1956\u001b[0m, in \u001b[0;36myticks\u001b[1;34m(ticks, labels, minor, **kwargs)\u001b[0m\n\u001b[0;32m   1954\u001b[0m         l\u001b[38;5;241m.\u001b[39m_internal_update(kwargs)\n\u001b[0;32m   1955\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1956\u001b[0m     labels \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mset_yticklabels(labels, minor\u001b[38;5;241m=\u001b[39mminor, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1958\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m locs, labels\n",
      "File \u001b[1;32mc:\\Users\\faris\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_base.py:74\u001b[0m, in \u001b[0;36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_method(\u001b[38;5;28mself\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\faris\\anaconda3\\Lib\\site-packages\\matplotlib\\_api\\deprecation.py:297\u001b[0m, in \u001b[0;36mrename_parameter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    292\u001b[0m     warn_deprecated(\n\u001b[0;32m    293\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas been renamed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m since Matplotlib \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msince\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    295\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor the old name will be dropped %(removal)s.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    296\u001b[0m     kwargs[new] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(old)\n\u001b[1;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\faris\\anaconda3\\Lib\\site-packages\\matplotlib\\axis.py:1969\u001b[0m, in \u001b[0;36mAxis.set_ticklabels\u001b[1;34m(self, labels, minor, fontdict, **kwargs)\u001b[0m\n\u001b[0;32m   1965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(locator, mticker\u001b[38;5;241m.\u001b[39mFixedLocator):\n\u001b[0;32m   1966\u001b[0m     \u001b[38;5;66;03m# Passing [] as a list of labels is often used as a way to\u001b[39;00m\n\u001b[0;32m   1967\u001b[0m     \u001b[38;5;66;03m# remove all tick labels, so only error for > 0 labels\u001b[39;00m\n\u001b[0;32m   1968\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1969\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1970\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of FixedLocator locations\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1971\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), usually from a call to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1972\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m set_ticks, does not match\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1973\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the number of labels (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(labels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1974\u001b[0m     tickd \u001b[38;5;241m=\u001b[39m {loc: lab \u001b[38;5;28;01mfor\u001b[39;00m loc, lab \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs, labels)}\n\u001b[0;32m   1975\u001b[0m     func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_with_dict, tickd)\n",
      "\u001b[1;31mValueError\u001b[0m: The number of FixedLocator locations (30), usually from a call to set_ticks, does not match the number of labels (4)."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0kUlEQVR4nO3deXRT5b7G8Se0NK3QlqnjpWWUWRABkephONZCZTGoRxSR6TifgkKPXMArAhe1oKicqwgOQHFAFC8FRKUytYiAQqEXUCizjGUQaBkkYLvvHy56CARoyk7SJN/PWvkjO2/2/vWVZX5rD89rMQzDEAAAgJtU8HQBAADAv9B8AAAAt6L5AAAAbkXzAQAA3IrmAwAAuBXNBwAAcCuaDwAA4FY0HwAAwK0CPV3A5YqLi3Xw4EGFhobKYrF4uhwAAFAKhmHo1KlTio2NVYUK1z63Ue6aj4MHDyouLs7TZQAAgDLYt2+fatasec0x5a75CA0NlfRn8WFhYR6uBgAAlEZhYaHi4uJKfsevpdw1HxcvtYSFhdF8AADgZUpzywQ3nAIAALei+QAAAG5F8wEAANyK5gMAALgVzQcAAHArmg8AAOBWNB8AAMCtaD4AAIBb0XwAAAC3ovkAAABuRfMBAADciuYDAAC4Fc0HAABwK5oPAADgVk41H2lpaWrTpo1CQ0MVGRmpnj17Ki8vz27Mzp07dd999ykiIkJhYWHq1auXDh8+bGrRAADAeznVfGRnZyslJUVr1qzR4sWLdeHCBSUlJenMmTOSpDNnzigpKUkWi0XLli3TDz/8oPPnz6tbt24qLi52yR8AAAC8i8UwDKOsXz569KgiIyOVnZ2t9u3b67vvvlNycrJOnDihsLAwSVJBQYGqVq2q7777TomJidfdZ2FhocLDw1VQUFCyDwAAUL458/t9Q/d8FBQUSJKqVasmSbLZbLJYLLJarSVjgoODVaFCBa1cudLhPmw2mwoLC+1eAADAd5W5+SguLtaQIUN05513qlmzZpKkO+64Q5UqVdLw4cN19uxZnTlzRs8//7yKiop06NAhh/tJS0tTeHh4ySsuLq6sJQEAAC9Q5uYjJSVFmzdv1uzZs0u2RUREaM6cOfrqq69UuXJlhYeH6+TJk7rttttUoYLjQ40cOVIFBQUlr3379pW1JAAA4AUCy/KlQYMGaeHChVqxYoVq1qxp91lSUpJ27typY8eOKTAwUFWqVFF0dLTq1q3rcF9Wq9XuMg0AAPBtTjUfhmFo8ODBysjIUFZWlurUqXPVsTVq1JAkLVu2TEeOHFH37t1vrFIAAOATnGo+UlJSNGvWLM2fP1+hoaHKz8+XJIWHhyskJESSNGPGDDVu3FgRERFavXq1nnvuOQ0dOlQNGzY0v3oAAOB1nHrU1mKxONw+Y8YMDRgwQJI0YsQIpaen6/jx46pdu7aefvppDR069KrfvRyP2gIA4H2c+f2+oZwPV6D5AADA+7gs56M08er5+fnq27evoqOjValSJd1222363//9X6f/iGajM53+DgAAKP9MjVeXpH79+ikvL08LFizQpk2bdP/996tXr17asGGD6cUDAADvY2q8uiRVrlxZU6ZMUd++fUvGVa9eXRMmTNDjjz9+3X1ePG0TN+QL7X3rwbKWBgAA3Mhj8eqSlJCQoM8//1zHjx9XcXGxZs+erXPnzqljx44O90G8OgAA/sXUeHVJ+uKLL3ThwgVVr15dVqtVTz31lDIyMlS/fn2H+yFeHQAA/2JqvLokjRo1SidPntSSJUu0bt06paamqlevXtq0aZPD/RCvDgCAfzE1Xn3nzp165513tHnzZjVt2lSS1KJFC33//feaPHmypk6desW+iFcHAMC/mBqvfvbsWUm6YhG5gIAAFRcX32CpAADAF5gar96oUSPVr19fTz31lCZOnKjq1atr3rx5Wrx4sRYuXOiSPwAAAHgX0+PVt2/frhEjRmjlypU6ffq06tevr+eff97u0dtrIeEUAADvQ7w6AABwK2d+v5267JKWlqa5c+dq69atCgkJUUJCgiZMmFCyYu2ePXuuuA/koi+++EIPPlj60LBmozNVwXqTM+W5zZ7xXT1dAgAAXsvUePW4uDgdOnTI7jV27FhVrlxZycnJLvkDAACAd3HqzMeiRYvs3qenpysyMlI5OTlq3769AgICFB0dbTcmIyNDvXr1UuXKlW+8WgAA4PVMj1e/VE5OjnJzc/XYY4/dyGEAAIAPKVPImHT1ePVLTZs2TY0bN1ZCQsJV92Oz2WSz2Ures7YLAAC+zfR49Yt+//13zZo167pnPVjbBQAA/1Km5uNivPry5cvt4tUv9eWXX+rs2bPq16/fNffF2i4AAPgXU+PVLzVt2jR1795dERER19wna7sAAOBfTI1Xv2jHjh1asWKFvvnmG3OrBQAAXs/0eHVJeuGFF/TJJ59oz549Vywydz0knAIA4H2IVwcAAG7lsnh1d7rReHUi0AEAKJ+cuiaSlpamNm3aKDQ0VJGRkerZs6fy8vKuGLd69Wr99a9/VaVKlRQWFqb27dvr999/N61oAADgvUxd20X6s/Ho0qWLkpKS9NNPP2nt2rUaNGiQ0/d+AAAA33RD93wcPXpUkZGRys7OVvv27SVJd9xxh+655x6NGzeuTPu8eM0obsgXXHYBAMBLOHPPh6lruxw5ckQ//vijIiMjlZCQoKioKHXo0EErV6686j5sNpsKCwvtXgAAwHeVuflwtLbLrl27JEljxozRE088oUWLFum2227T3Xffre3btzvcD/HqAAD4F1PXdikuLpYkPfXUUxo4cKBatmypt956Sw0bNtT06dMd7od4dQAA/EuZHrW9uLbLihUr7NZ2iYmJkSQ1adLEbnzjxo21d+9eh/siXh0AAP/i1JkPwzA0aNAgZWRkaNmyZVes7VK7dm3FxsZe8fjttm3bVKtWrRuvFgAAeD1T13axWCwaNmyYRo8erRYtWujWW2/VzJkztXXrVn355ZdOFbZ5bGcSTgEA8EFONR9TpkyRJHXs2NFu+6VruwwZMkTnzp3T0KFDdfz4cbVo0UKLFy9WvXr1TCkYAAB4N9Z2AQAAN8xlOR+liVfv2LGjLBaL3evpp592+o9oNjpTtUd8rdojvnb6uwAAoPwyPV5dkp544gkdOnSo5PXaa6+ZWjQAAPBeTt3zsWjRIrv36enpioyMVE5OTkm8uiTddNNNio6ONqdCAADgU0yNV7/o008/VY0aNdSsWTONHDlSZ8+eveo+iFcHAMC/lClkTHIcry5JjzzyiGrVqqXY2Fht3LhRw4cPV15enubOnetwP2lpaRo7dmxZywAAAF6mzE+7PPPMM/r222+1cuVKu5TTyy1btkx33323duzY4fBxW5vNJpvNVvK+sLBQcXFxdqvaskItAADlmzNPu5gar+5I27ZtJemqzQfx6gAA+Benmg/DMDR48GBlZGQoKyvrinh1R3JzcyX9e90XAADg30yNV9+5c6dmzZqle++9V9WrV9fGjRs1dOhQtW/fXs2bN3fJHwAAALyLU/d8WCwWh9svxqvv27dPjz76qDZv3qwzZ84oLi5O9913n1588cVSp5WScAoAgPdx2T0f1+tT4uLilJ2d7cwuAQCAnzE9Xv0iwzCUnJwsi8WiefPmmVErAADwAS6JV5ekSZMmXfUyDQAA8F8uiVfPzc3VG2+8oXXr1vGUCwAAsFPmhFPJcbz62bNn9cgjj2jy5MmlWt/FUcgYAADwXWVe2+Vq8epDhw5VQkKCevToUar9pKWlKTw8vOQVFxdX1pIAAIAXKPOZj5SUFG3evFkrV64s2bZgwQItW7ZMGzZsKPV+Ro4cqdTU1JL3F+PVAQCAbyrTmY+L8erLly+3i1dftmyZdu7cqSpVqigwMFCBgX/2Ng888IA6duzocF9Wq1VhYWF2LwAA4LucChm7PF795ptvtvs8Pz9fx44ds9t2yy236F//+pe6detWqjh2QsYAAPA+LgsZu168enR0tMObTOPj40vVeAAAAN/n1GWXKVOmqKCgQB07dlRMTEzJ6/PPP3dVfQAAwMeYGq9u1ncAAIDvcqr5SEtL09y5c7V161aFhIQoISFBEyZMUMOGDUvGPPXUU1qyZIkOHjyoypUrl4xp1KiRU4U1G52pCtabnPqOWfaM7+qR4wIA4A9Mj1dv1aqVZsyYoS1btigzM1OGYSgpKUlFRUWmFw8AALyPU0+7XO7o0aOKjIxUdna2Xbz6pTZu3KgWLVpox44dqlev3nX3efFu2bghX3DmAwAAL+HM0y5lTjiVHMerX+rMmTOaMWOG6tSpQ3AYAACQ5IJ4dUl69913VblyZVWuXFnffvutFi9erKCgIIf7sdlsKiwstHsBAADfVebm42K8+uzZs6/4rE+fPtqwYYOys7PVoEED9erVS+fOnXO4H9Z2AQDAv5Tpno9BgwZp/vz5WrFixXXDw86fP6+qVavqww8/VO/eva/43NGqtnFxcdzzAQCAF3FZwunl8eqlSS01DEOGYdg1GJeyWq2yWq3OlAEAALyYqfHqu3bt0ueff66kpCRFRERo//79Gj9+vEJCQnTvvfe65A8AAADexanLLhaLxeH2GTNmaMCAATp48KAef/xx5eTk6MSJE4qKilL79u310ksv2QWRXQsLywEA4H1cetnlWmJjY/XNN984s0sAAOBnnGo+3MmT8erejJtlAQDlnVOP2qalpalNmzYKDQ1VZGSkevbsqby8vJLPjx8/rsGDB6thw4YKCQlRfHy8nn322ZIwMgAAAFPXdjl48KAOHjyoiRMnavPmzUpPT9eiRYv02GOPuaR4AADgfVy+tsucOXP06KOP6syZMwoMvP5VnvKwtos347ILAMATXHbD6eWut7bLxTFhYWFXbTwchYwBAADf5ZK1XS46duyYxo0bpyeffPKq+yFeHQAA/+KStV2kP89gdO3aVU2aNNGYMWOuup+RI0eqoKCg5LVv376ylgQAALxAmS67DBo0SAsXLtSKFStUs2bNKz4/deqUunTpotDQUGVkZKhixYpX3Rfx6gAA+BenznwYhqFBgwYpIyNDy5Ytc7i2S2FhoZKSkhQUFKQFCxYoODjYtGIBAID3c+ppl3/84x8la7tcGpd+cW2Xi43H2bNnlZGRoUqVKpWMiYiIUEBAwHWPQbw6AADex5nfb1PXdsnKylKnTp0cjtm9e7dq16593WPQfAAA4H08trZLx44drzsGAAD4N6eaj7S0NM2dO1dbt25VSEiIEhISNGHCBLtLMO+//75mzZql9evX69SpUzpx4oSqVKnidGGeWNuFgC4AAFzP1Hh1STp79qy6dOmiF154wfRiAQCA93PqzMeiRYvs3qenpysyMlI5OTkl8epDhgyRJGVlZZlSIAAA8C0uj1e/HuLVAQDwLy6NVy8N4tUBAPAvLotXLy3i1QEA8C8uiVd3BvHqAAD4F6dzPgYPHqyMjAxlZWU5jFcHAAC4Fqeaj5SUlJJ49dDQUOXn50v6d7y6JOXn5ys/P187duyQJG3atEmhoaGKj4+/oRtTAQCAbzA1Xl2SxowZo7Fjx15zzLUQrw4AgPdx2dou7kDzAQCA93HZ2i6liVc/d+6c/vnPf2r27Nmy2Wzq3Lmz3n33XUVFRTn1R7g6Xp0odQAAPMP0ePWhQ4fqq6++0pw5c5Sdna2DBw/q/vvvN71wAADgnW7ossvRo0cVGRmp7OxstW/fXgUFBYqIiNCsWbP0t7/9TZK0detWNW7cWKtXr9Ydd9xx3X1ePG0TN+QLznwAAOAlnLnsUuaQMenKePWcnBxduHBBiYmJJWMaNWqk+Ph4rV692uE+bDabCgsL7V4AAMB3mRqvnp+fr6CgIFWpUsVubFRUVMljuZcjXh0AAP9CvDoAAHArU+PVo6Ojdf78eZ08edLu7Mfhw4cVHR3tcF/EqwMA4F+cOvNhGIYGDRqkjIwMLVu27Ip49VatWqlixYpaunRpyba8vDzt3btX7dq1M6diAADg1UyNVw8PD9djjz2m1NRUVatWTWFhYRo8eLDatWtXqiddAACA7zM9Xv1iyNhnn31mFzJ2tcsulyPhFAAA70O8OgAAcCuXxau70+Xx6oSCAQDgG5x+1HbFihXq1q2bYmNjZbFYNG/ePLvPDx8+rAEDBig2NlY33XSTunTpou3bt5tVLwAA8HJONx9nzpxRixYtNHny5Cs+MwxDPXv21K5duzR//nxt2LBBtWrVUmJiot36LwAAwH85fdklOTlZycnJDj/bvn271qxZo82bN6tp06aSpClTpig6OlqfffaZHn/88RurFgAAeL0bWtvlcjabTZIUHBz87wNUqCCr1aqVK1de9Tus7QIAgP8wtfm4uIjcyJEjdeLECZ0/f14TJkzQ/v37dejQIYffYW0XAAD8i6nNR8WKFTV37lxt27ZN1apV00033aTly5crOTlZFSo4PhRruwAA4F9Mf9S2VatWys3NVUFBgc6fP6+IiAi1bdtWrVu3djietV0AAPAvpp75uFR4eLgiIiK0fft2rVu3Tj169HDVoQAAgBdx+szH6dOntWPHjpL3u3fvVm5urqpVq6b4+HjNmTNHERERio+P16ZNm/Tcc8+pZ8+eSkpKcuo4m8d2JuEUAAAf5HTzsW7dOnXq1KnkfWpqqiSpf//+Sk9P16FDh5SamqrDhw8rJiZG/fr106hRo8yrGAAAeDXWdgEAADfMmd9v0+PVT58+rUGDBqlmzZoKCQlRkyZNNHXqVGcPAwAAfJSp8erSn5dhFi1apE8++URbtmzRkCFDNGjQIC1YsOCGiwUAAN7P1Hh1SVq1apX69++vjh07SpKefPJJvffee/rpp5/UvXv3MhcKAAB8g+mP2iYkJGjBggU6cOCADMPQ8uXLtW3btqs+7UK8OgAA/sX05uPtt99WkyZNVLNmTQUFBalLly6aPHmy2rdv73A88eoAAPgXlzQfa9as0YIFC5STk6M33nhDKSkpWrJkicPxxKsDAOBfTI1X//333/XCCy8oIyNDXbt2lSQ1b95cubm5mjhxohITE6/4DvHqAAD4F1PPfFy4cEEXLly4YhG5gIAAFRcXm3koAADgpUyPV+/QoYOGDRumkJAQ1apVS9nZ2froo4/05ptvmlo4AADwTk4nnGZlZdnFq190MV49Pz9fI0eO1Hfffafjx4+rVq1aevLJJzV06FBZLJbr7p+EUwAAvI8zv9/EqwMAgBvm0Xh1i8Xi8PX66687eygAAOCDTI9XP3TokN1r+vTpslgseuCBB264WAAA4P1Mj1ePjo62ez9//nx16tRJdevWdb46AADgc0zN+bjc4cOH9fXXX2vmzJlXHWOz2WSz2UreE68OAIBvMz3h9FIzZ85UaGio7r///quOIV4dAAD/4tLmY/r06erTp4+Cg4OvOoZ4dQAA/IvLLrt8//33ysvL0+eff37NccSrAwDgX1x25mPatGlq1aqVWrRo4apDAAAAL2R6vLr0502jc+bM0RtvvGFepQAAwCc43XysW7fOLl49NTVV0r/j1SVp9uzZMgxDvXv3NqdKAADgM4hXBwAAN8yj8eqStGXLFnXv3l3h4eGqVKmS2rRpo7179zp7KAAA4INMj1ffuXOn7rrrLjVq1EhZWVnauHGjRo0adc3HbQEAgP+4ocsuFotFGRkZ6tmzZ8m2hx9+WBUrVtTHH39cpn1y2QUAAO/j0ssu11JcXKyvv/5aDRo0UOfOnRUZGam2bds6vDQDAAD8k6nNx5EjR3T69GmNHz9eXbp00Xfffaf77rtP999/v7Kzsx1+x2azqbCw0O4FAAB8l6kJp8XFxZKkHj16aOjQoZKkW2+9VatWrdLUqVPVoUOHK76TlpamsWPHmlkGAAAox0w981GjRg0FBgaqSZMmdtsbN2581addWNsFAAD/YuqZj6CgILVp00Z5eXl227dt26ZatWo5/A5ruwAA4F9Mj1cfNmyYHnroIbVv316dOnXSokWL9NVXXykrK8vMugEAgJdy+lHbrKwsu3j1iy6NV58+fbrS0tK0f/9+NWzYUGPHjlWPHj1KtX8etQUAwPs48/tNvDoAALhhHsv5AAAAuB7T13YZMGCALBaL3atLly5m1QsAALyc6Wu7SFKXLl106NChktdnn312Q0UCAADf4fTTLsnJyUpOTr7mGKvVqujo6DIXBQAAfJdL7vnIyspSZGSkGjZsqGeeeUa//fbbVccSrw4AgH8xvfno0qWLPvroIy1dulQTJkxQdna2kpOTVVRU5HB8WlqawsPDS15xcXFmlwQAAMqRG3rU1mKxKCMjQz179rzqmF27dqlevXpasmSJ7r777is+t9lsstlsJe8LCwsVFxfHo7YAAHiRcvWobd26dVWjRg27VNRLWa1WhYWF2b0AAIDvcnnzsX//fv3222+KiYlx9aEAAIAXMHVtl2rVqmns2LF64IEHFB0drZ07d+o///M/Vb9+fXXu3NnUwgEAgHdyuvlYt26d3douqampkv5c22XKlCnauHGjZs6cqZMnTyo2NlZJSUkaN24cK9cCAABJrO0CAABM4NIbTq8Xr36pp59+WhaLRZMmTXL2MAAAwEe5JF5dkjIyMrRmzRrFxsaWuTgAAOB7XBKvfuDAAQ0ePFiZmZnq2rVrmYsDAAC+x+nm43qKi4vVt29fDRs2TE2bNr3ueEchYwAAwHeZnvMxYcIEBQYG6tlnny3VeOLVAQDwL6Y2Hzk5OfrXv/6l9PR0WSyWUn1n5MiRKigoKHnt27fPzJIAAEA5Y2rz8f333+vIkSOKj49XYGCgAgMD9euvv+qf//ynateu7fA7xKsDAOBfTL3no2/fvkpMTLTb1rlzZ/Xt21cDBw4081AAAMBLmRqvHh8fr+rVq9uNr1ixoqKjo9WwYcMbrxYAAHg9U+PV09PTTSsMAAD4Jqebj44dO8qZRPY9e/Y4ewgAAODDnG4+VqxYoddff105OTk6dOiQMjIy1LNnz5LPx4wZo9mzZ2vfvn0KCgpSq1at9Morr6ht27ZOHafZ6ExVsN7kbHnaM55QMwAAyjPT49UbNGigd955R5s2bdLKlStVu3ZtJSUl6ejRozdcLAAA8H6mx6s/8sgjdu/ffPNNTZs2TRs3btTdd9/tfIUAAMCnmB6vfqnz58/r/fffV3h4uFq0aOFwDPHqAAD4F9Pj1SVp4cKFqly5soKDg/XWW29p8eLFqlGjhsOxxKsDAOBfXNJ8dOrUSbm5uVq1apW6dOmiXr166ciRIw7HEq8OAIB/cUnzUalSJdWvX1933HGHpk2bpsDAQE2bNs3hWOLVAQDwLy5pPi5XXFxsd18HAADwX6bGq1evXl2vvPKKunfvrpiYGB07dkyTJ0/WgQMH9OCDD5paOAAA8E6mxqtPnTpVW7du1cyZM3Xs2DFVr15dbdq00ffff6+mTZs6dZzNYztzCQYAAB9kMZzJSneDwsJChYeHq6CggOYDAAAv4czvt9P3fKxYsULdunVTbGysLBaL5s2bV/LZhQsXNHz4cN1yyy2qVKmSYmNj1a9fPx08eNDpP6LZ6EzVHvG1098DAADlm6nx6mfPntX69es1atQorV+/XnPnzlVeXp66d+9uSrEAAMD7mRqvHh4ersWLF9tte+edd3T77bdr7969io+PL1uVAADAZ7j8UduCggJZLBZVqVLF1YcCAABewKVru5w7d07Dhw9X7969r3rzCWu7AADgX1x25uPChQvq1auXDMPQlClTrjqOtV0AAPAvLmk+LjYev/76qxYvXnzNR25Y2wUAAP9i+mWXi43H9u3btXz5clWvXv2a461Wq6xWq9llAACAcsrUePWYmBj97W9/0/r167Vw4UIVFRUpPz9fklStWjUFBQWZVzkAAPBKTiecZmVl2cWrX9S/f3+NGTNGderUcfi95cuXq2PHjtfdPwmnAAB4H2d+v50+89GxY0ddq18pZ2ntAACgnHF5zgcAAMClTF3bRZLmzp2rpKQkVa9eXRaLRbm5uSaVCgAAfIGpa7tc/Pyuu+7ShAkTbrg4AADge0xd20WS+vbtK0nas2dPmYsCAAC+y6Xx6qVBvDoAAP7F4zecEq8OAIB/8XjzQbw6AAD+xeOXXYhXBwDAv3j8zAcAAPAvpq7tEh8fr+PHj2vv3r06ePCgJCkvL0+SFB0drejoaJPKBgAA3srpMx/r1q1Ty5Yt1bJlS0lSamqqWrZsqZdeekmStGDBArVs2VJdu3aVJD388MNq2bKlpk6damLZAADAWzm9sJyrsbAcAADex5nfb9Pj1Q3D0EsvvaSYmBiFhIQoMTFR27dvd/YwajY6U7VHfK3aI752+rsAAKD8Mj1e/bXXXtP//M//aOrUqfrxxx9VqVIlde7cWefOnbvhYgEAgPczNV7dMAxNmjRJL774onr06CFJ+uijjxQVFaV58+bp4YcfvrFqAQCA1zP1Udvdu3crPz9fiYmJJdvCw8PVtm1brV692uF3bDabCgsL7V4AAMB3mdp85OfnS5KioqLstkdFRZV8djni1QEA8C8eDxkjXh0AAP9iavNxMUTs8OHDdtsPHz581YAxq9WqsLAwuxcAAPBdpjYfderUUXR0tJYuXVqyrbCwUD/++KPatWtn5qEAAICXMj1efciQIXr55Zd18803q06dOho1apRiY2PVs2dPM+sGAABeyumE06ysLHXq1OmK7f3791d6eroMw9Do0aP1/vvv6+TJk7rrrrv07rvvqkGDBqXaPwmnAAB4H2d+v4lXBwAAN8yl8eqlcerUKQ0ZMkS1atVSSEiIEhIStHbtWlccCgAAeBmXNB+PP/64Fi9erI8//libNm1SUlKSEhMTdeDAAVccDgAAeBHTL7v8/vvvCg0N1fz589W1a9eS7a1atVJycrJefvnla36fyy4AAHgfZ36/nX7a5Xr++OMPFRUVKTg42G57SEiIVq5cecV4m80mm81W8p54dQAAfJvpl11CQ0PVrl07jRs3TgcPHlRRUZE++eQTrV69WocOHbpiPPHqAAD4F5c87bJz5079/e9/14oVKxQQEKDbbrtNDRo0UE5OjrZs2WI31tGZj7i4OC67AADgRTx62UWS6tWrp+zsbJ05c0aFhYWKiYnRQw89pLp1614x1mq1ymq1uqIMAABQDrl0YblKlSopJiZGJ06cUGZmpnr06OHKwwEAAC/gkjMfmZmZMgxDDRs21I4dOzRs2DA1atRIAwcOdMXhAACAF3HJmY+CggKlpKSoUaNG6tevn+666y5lZmaqYsWKrjgcAADwIsSrAwCAG+bxeHUzNBud6ekSAACAC5jefBQVFWnUqFGqU6eOQkJCVK9ePY0bN07l7AQLAADwENNvOJ0wYYKmTJmimTNnqmnTplq3bp0GDhyo8PBwPfvss2YfDgAAeBnTm49Vq1apR48eJeu61K5dW5999pl++uknsw8FAAC8kOmXXRISErR06VJt27ZNkvR///d/WrlypZKTkx2Ot9lsKiwstHsBAADfZfqZjxEjRqiwsFCNGjVSQECAioqK9Morr6hPnz4Ox6elpWns2LFmlwEAAMop0898fPHFF/r00081a9YsrV+/XjNnztTEiRM1c+ZMh+NHjhypgoKCkte+ffvMLgkAAJQjpp/5GDZsmEaMGKGHH35YknTLLbfo119/VVpamvr373/FeNZ2AQDAv5h+5uPs2bOqUMF+twEBASouLjb7UAAAwAuZfuajW7dueuWVVxQfH6+mTZtqw4YNevPNN/X3v//dqf1sHtvZ7NIAAEA5YHq8+qlTpzRq1ChlZGToyJEjio2NVe/evfXSSy8pKCjout8nXh0AAO/jzO83a7sAAIAb5szvt+mXXWrXrq1ff/31iu3/+Mc/NHny5FLvp9noTFWw3mRmaQAA+L0947t6ugTzm4+1a9eqqKio5P3mzZt1zz336MEHHzT7UAAAwAuZ3nxERETYvR8/frzq1aunDh06mH0oAADghUxvPi51/vx5ffLJJ0pNTZXFYnE4xmazyWazlbwnXh0AAN9mes7HpebNm6eTJ09qwIABVx2Tlpam8PDwkldcXJwrSwIAAB7m0uZj2rRpSk5OVmxs7FXHEK8OAIB/cdlll19//VVLlizR3LlzrzmOeHUAAPyLy858zJgxQ5GRkera1fOP9AAAgPLDJc1HcXGxZsyYof79+ysw0KX3tAIAAC/jks5gyZIl2rt3r9PruVxq89jOJJwCAOCDXNJ8JCUlqZyltgMAgHLCJZddDhw4oEcffVTVq1dXSEiIbrnlFq1bt84VhwIAAF7G9DMfJ06c0J133qlOnTrp22+/VUREhLZv366qVauafSgAAOCFTG8+JkyYoLi4OM2YMaNkW506dcw+DAAA8FKmX3ZZsGCBWrdurQcffFCRkZFq2bKlPvjgg6uOt9lsKiwstHsBAADfZXrzsWvXLk2ZMkU333yzMjMz9cwzz+jZZ5/VzJkzHY4nXh0AAP9iMUx+LCUoKEitW7fWqlWrSrY9++yzWrt2rVavXn3FeEcLy8XFxamgoIBHbQEA8BKFhYUKDw8v1e+36Wc+YmJi1KRJE7ttjRs31t69ex2Ot1qtCgsLs3sBAADfZXrzceeddyovL89u27Zt21SrVi2zDwUAALyQ6c3H0KFDtWbNGr366qvasWOHZs2apffff18pKSlmHwoAAHgh05uPNm3aKCMjQ5999pmaNWumcePGadKkSerTp4/ZhwIAAF7I9BtOb5QzN6wAAIDywaM3nI4ZM0YWi8Xu1ahRI7MPAwAAvJRLFpZr2rSplixZ8u+DBLrkMAAAwAu5pCsIDAxUdHS0K3YNAAC8nEtWtd2+fbtiY2NVt25d9enT56oZHwAAwP+Yfuajbdu2Sk9PV8OGDXXo0CGNHTtWf/nLX7R582aFhoZeMd5RwikAAPBdLn/a5eTJk6pVq5befPNNPfbYY1d8PmbMGI0dO/aK7TztAgCA9/Do0y6Xq1Kliho0aKAdO3Y4/HzkyJEqKCgoee3bt8/VJQEAAA9yefNx+vRp7dy5UzExMQ4/Z20XAAD8i+nNx/PPP6/s7Gzt2bNHq1at0n333aeAgAD17t3b7EMBAAAvZPoNp/v371fv3r3122+/KSIiQnfddZfWrFmjiIgIsw8FAAC8kOnNx+zZs83eJQAA8CEuv+cDAADgUi5vPsaPHy+LxaIhQ4a4+lAAAMALuLT5WLt2rd577z01b97clYcBAABexGXNx+nTp9WnTx998MEHqlq1qqsOAwAAvIzLmo+UlBR17dpViYmJ1xxns9lUWFho9wIAAL7LJavazp49W+vXr9fatWuvOzYtLc1hvDoAAPBNpp/52Ldvn5577jl9+umnCg4Ovu544tUBAPAvpi8sN2/evJJU04uKiopksVhUoUIF2Ww2u88u58zCNAAAoHxw5vfb9Msud999tzZt2mS3beDAgWrUqJGGDx9+zcYDAAD4PtObj9DQUDVr1sxuW6VKlVS9evUrtgMAAP9DwikAAHArlzztcrmsrCx3HAYAAHgB0898TJkyRc2bN1dYWJjCwsLUrl07ffvtt2YfBgAAeCnTm4+aNWtq/PjxysnJ0bp16/TXv/5VPXr00M8//2z2oQAAgBcy/VFbR6pVq6bXX39djz322HXH8qgtAADex6OP2l6qqKhIc+bM0ZkzZ9SuXTuHY2w2m2w2W8l74tUBAPBtLnnaZdOmTapcubKsVquefvppZWRkqEmTJg7HpqWlKTw8vOQVFxfnipIAAEA54ZLLLufPn9fevXtVUFCgL7/8Uh9++KGys7MdNiCOznzExcVx2QUAAC/izGUXt9zzkZiYqHr16um999677lju+QAAwPs48/vtlpCx4uJiu7MbAADAf5l+w+nIkSOVnJys+Ph4nTp1SrNmzVJWVpYyMzPNPhQAAPBCpjcfR44cUb9+/XTo0CGFh4erefPmyszM1D333GP2oQAAgBcyvfmYNm2a2bsEAAA+xPR7PtLS0tSmTRuFhoYqMjJSPXv2VF5entmHAQAAXsr05iM7O1spKSlas2aNFi9erAsXLigpKUlnzpwx+1AAAMALufxR26NHjyoyMlLZ2dlq3779dcfzqC0AAN6n3MSrS1JBQYGkP9d3cYR4dQAA/ItLcz6Ki4s1ZMgQ3XnnnWrWrJnDMcSrAwDgX1x62eWZZ57Rt99+q5UrV6pmzZoOxxCvDgCA9ysXl10GDRqkhQsXasWKFVdtPCTJarXKarW6qgwAAFDOmN58GIahwYMHKyMjQ1lZWapTp47ZhwAAAF7M9OYjJSVFs2bN0vz58xUaGqr8/HxJUnh4uEJCQsw+HAAA8DKm3/NhsVgcbp8xY4YGDBhw3e/zqC0AAN7Ho/d8uDg2BAAAeDmX53yUVbPRmapgvcmp7+wZ39VF1QAAALOYnvOxYsUKdevWTbGxsbJYLJo3b57ZhwAAAF7M9ObjzJkzatGihSZPnmz2rgEAgA8w/bJLcnKykpOTzd4tAADwER6/54O1XQAA8C8uXdulNFjbBQAA/+Lx5mPkyJEqKCgoee3bt8/TJQEAABfy+GUX1nYBAMC/ePzMBwAA8C+mn/k4ffq0duzYUfJ+9+7dys3NVbVq1RQfH1/q/Wwe25l4dQAAfJDpzce6devUqVOnkvepqamSpP79+ys9Pd3swwEAAC9jevPRsWNH1ncBAABX5bJ7PiZPnqzatWsrODhYbdu21U8//eSqQwEAAC/ikubj888/V2pqqkaPHq3169erRYsW6ty5s44cOeKKwwEAAC/ikubjzTff1BNPPKGBAweqSZMmmjp1qm666SZNnz7dFYcDAABexPTm4/z588rJyVFiYuK/D1KhghITE7V69eorxttsNhUWFtq9AACA7zK9+Th27JiKiooUFRVltz0qKkr5+flXjCdeHQAA/+LxkDHi1QEA8C+mP2pbo0YNBQQE6PDhw3bbDx8+rOjo6CvGE68OAIB/Mf3MR1BQkFq1aqWlS5eWbCsuLtbSpUvVrl07sw8HAAC8jEsWlktNTVX//v3VunVr3X777Zo0aZLOnDmjgQMHuuJwAADAi7ik+XjooYd09OhRvfTSS8rPz9ett96qRYsWXXETKgAA8D8Wo5xloRcWFio8PFwFBQUsLAcAgJdw5vfb40+7AAAA/0LzAQAA3IrmAwAAuBXNBwAAcCuaDwAA4FY0HwAAwK1oPgAAgFvRfAAAALei+QAAAG5F8wEAANyK5gMAALgVzQcAAHArmg8AAOBWgZ4u4HIXF9ktLCz0cCUAAKC0Lv5uX/wdv5Zy13z89ttvkqS4uDgPVwIAAJx16tQphYeHX3NMuWs+qlWrJknau3fvdYv3d4WFhYqLi9O+ffsUFhbm6XLKLeapdJin0mOuSod5Kh1fmSfDMHTq1CnFxsZed2y5az4qVPjzNpTw8HCv/o/gTmFhYcxVKTBPpcM8lR5zVTrMU+n4wjyV9qQBN5wCAAC3ovkAAABuVe6aD6vVqtGjR8tqtXq6lHKPuSod5ql0mKfSY65Kh3kqHX+cJ4tRmmdiAAAATFLuznwAAADfRvMBAADciuYDAAC4Fc0HAABwK480H5MnT1bt2rUVHBystm3b6qeffrrm+Dlz5qhRo0YKDg7WLbfcom+++cZNlXqeM3P1888/64EHHlDt2rVlsVg0adIk9xXqYc7M0wcffKC//OUvqlq1qqpWrarExMTr/hv0Fc7M09y5c9W6dWtVqVJFlSpV0q233qqPP/7YjdV6lrP/n7po9uzZslgs6tmzp2sLLCecmaf09HRZLBa7V3BwsBur9Rxn/z2dPHlSKSkpiomJkdVqVYMGDXzrt89ws9mzZxtBQUHG9OnTjZ9//tl44oknjCpVqhiHDx92OP6HH34wAgICjNdee8345ZdfjBdffNGoWLGisWnTJjdX7n7OztVPP/1kPP/888Znn31mREdHG2+99ZZ7C/YQZ+fpkUceMSZPnmxs2LDB2LJlizFgwAAjPDzc2L9/v5srdy9n52n58uXG3LlzjV9++cXYsWOHMWnSJCMgIMBYtGiRmyt3P2fn6qLdu3cb//Ef/2H85S9/MXr06OGeYj3I2XmaMWOGERYWZhw6dKjklZ+f7+aq3c/ZebLZbEbr1q2Ne++911i5cqWxe/duIysry8jNzXVz5a7j9ubj9ttvN1JSUkreFxUVGbGxsUZaWprD8b169TK6du1qt61t27bGU0895dI6ywNn5+pStWrV8pvm40bmyTAM448//jBCQ0ONmTNnuqrEcuFG58kwDKNly5bGiy++6IryypWyzNUff/xhJCQkGB9++KHRv39/v2g+nJ2nGTNmGOHh4W6qrvxwdp6mTJli1K1b1zh//ry7SnQ7t152OX/+vHJycpSYmFiyrUKFCkpMTNTq1asdfmf16tV24yWpc+fOVx3vK8oyV/7IjHk6e/asLly4ULKooS+60XkyDENLly5VXl6e2rdv78pSPa6sc/Xf//3fioyM1GOPPeaOMj2urPN0+vRp1apVS3FxcerRo4d+/vlnd5TrMWWZpwULFqhdu3ZKSUlRVFSUmjVrpldffVVFRUXuKtvl3Np8HDt2TEVFRYqKirLbHhUVpfz8fIffyc/Pd2q8ryjLXPkjM+Zp+PDhio2NvaLJ9SVlnaeCggJVrlxZQUFB6tq1q95++23dc889ri7Xo8oyVytXrtS0adP0wQcfuKPEcqEs89SwYUNNnz5d8+fP1yeffKLi4mIlJCRo//797ijZI8oyT7t27dKXX36poqIiffPNNxo1apTeeOMNvfzyy+4o2S3K3aq2gDuNHz9es2fPVlZWlt/c+OaM0NBQ5ebm6vTp01q6dKlSU1NVt25ddezY0dOllRunTp1S37599cEHH6hGjRqeLqdca9eundq1a1fyPiEhQY0bN9Z7772ncePGebCy8qW4uFiRkZF6//33FRAQoFatWunAgQN6/fXXNXr0aE+XZwq3Nh81atRQQECADh8+bLf98OHDio6Odvid6Ohop8b7irLMlT+6kXmaOHGixo8fryVLlqh58+auLNPjyjpPFSpUUP369SVJt956q7Zs2aK0tDSfbj6cnaudO3dqz5496tatW8m24uJiSVJgYKDy8vJUr1491xbtAWb8P6pixYpq2bKlduzY4YoSy4WyzFNMTIwqVqyogICAkm2NGzdWfn6+zp8/r6CgIJfW7A5uvewSFBSkVq1aaenSpSXbiouLtXTpUrtu+FLt2rWzGy9Jixcvvup4X1GWufJHZZ2n1157TePGjdOiRYvUunVrd5TqUWb9eyouLpbNZnNFieWGs3PVqFEjbdq0Sbm5uSWv7t27q1OnTsrNzVVcXJw7y3cbM/5NFRUVadOmTYqJiXFVmR5Xlnm68847tWPHjpImVpK2bdummJgYn2g8JHnmUVur1Wqkp6cbv/zyi/Hkk08aVapUKXncqm/fvsaIESNKxv/www9GYGCgMXHiRGPLli3G6NGj/epRW2fmymazGRs2bDA2bNhgxMTEGM8//7yxYcMGY/v27Z76E9zC2XkaP368ERQUZHz55Zd2j/ydOnXKU3+CWzg7T6+++qrx3XffGTt37jR++eUXY+LEiUZgYKDxwQcfeOpPcBtn5+py/vK0i7PzNHbsWCMzM9PYuXOnkZOTYzz88MNGcHCw8fPPP3vqT3ALZ+dp7969RmhoqDFo0CAjLy/PWLhwoREZGWm8/PLLnvoTTOf25sMwDOPtt9824uPjjaCgIOP222831qxZU/JZhw4djP79+9uN/+KLL4wGDRoYQUFBRtOmTY2vv/7azRV7jjNztXv3bkPSFa8OHTq4v3A3c2aeatWq5XCeRo8e7f7C3cyZefqv//ovo379+kZwcLBRtWpVo127dsbs2bM9ULVnOPv/qUv5S/NhGM7N05AhQ0rGRkVFGffee6+xfv16D1Ttfs7+e1q1apXRtm1bw2q1GnXr1jVeeeUV448//nBz1a5jMQzD8NRZFwAA4H9Y2wUAALgVzQcAAHArmg8AAOBWNB8AAMCtaD4AAIBb0XwAAAC3ovkAAABuRfMBAADciuYDAAC4Fc0HAABwK5oPAADgVjQfAADArf4fmlBAA0oxbEIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the function to plot feature importances\n",
    "def plot_feature_importances_cancer(model):\n",
    "    n_features = X_train.shape[1]  # Number of features in the dataset\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), feature_names)  # Replace 'feature_names' with your actual feature names\n",
    "    plt.xlabel(\"Feature Importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.show()\n",
    "\n",
    "# Assuming feature_names is defined (if not, replace it with your actual feature names)\n",
    "# For example:\n",
    "# feature_names = X_train.columns if it's a pandas DataFrame, or manually define the names if X_train is a NumPy array.\n",
    "\n",
    "# Example feature names (if X_train is a NumPy array)\n",
    "feature_names = ['feature1', 'feature2', 'feature3', 'feature4']  # Replace with actual names\n",
    "\n",
    "# Call the function to plot feature importances\n",
    "plot_feature_importances_cancer(gbrt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strengths, Weaknesses, and Parameters of Gradient Boosted Decision Trees (GBDT) – Simplified:\n",
    "\n",
    "**Strengths**:\n",
    "1. **Powerful and Accurate**: Gradient boosted decision trees (GBDT) are **among the most powerful** models for supervised learning tasks like classification and regression. They often outperform other algorithms.\n",
    "2. **Good with Mixed Features**: They work well with both **binary** and **continuous** features (numbers and yes/no values), without the need for scaling (no need to standardize data).\n",
    "3. **No Scaling Required**: You don't need to normalize or scale your data like with other models (e.g., linear models).\n",
    "  \n",
    "**Weaknesses**:\n",
    "1. **Sensitive to Parameter Tuning**: GBDT models require careful **tuning of parameters** like the number of trees and learning rate. Poor choices can lead to suboptimal performance or overfitting.\n",
    "2. **Slow Training Time**: GBDT can take **longer to train** than some other algorithms, especially when the dataset is large.\n",
    "3. **Doesn’t Perform Well on High-Dimensional Sparse Data**: If your data has many features (high-dimensional) and a lot of zeros (sparse), GBDT may not perform as well. Models like linear classifiers tend to be better for that type of data.\n",
    "\n",
    "### Key Parameters to Tune:\n",
    "1. **n_estimators**: \n",
    "   - This is the **number of trees** in the model.\n",
    "   - A **larger number of trees** increases model complexity and accuracy, but can lead to **overfitting** (where the model is too specific to the training data).\n",
    "   - More trees also increase training time.\n",
    "   \n",
    "2. **learning_rate**:\n",
    "   - This controls how much each tree contributes to improving the overall model. It **adjusts the strength** of each new tree.\n",
    "   - **Lower learning_rate** values (e.g., 0.01) mean you need **more trees** (higher `n_estimators`), but can lead to a more robust model that is less prone to overfitting.\n",
    "   - **Higher learning_rate** values (e.g., 0.1 or higher) speed up learning but may lead to overfitting with fewer trees.\n",
    "\n",
    "3. **max_depth** (or **max_leaf_nodes**):\n",
    "   - These parameters control the **complexity of each tree**.\n",
    "   - Usually, GBDT trees are kept **shallow** (low max_depth), often **not deeper than 5 splits**. This keeps the model simple, prevents overfitting, and reduces training time.\n",
    "\n",
    "### Important Relationships:\n",
    "- **n_estimators** and **learning_rate** are connected. A **smaller learning_rate** requires **more trees** (higher `n_estimators`) to reach the same accuracy as a larger learning rate with fewer trees.\n",
    "- **max_depth** controls how complex each individual tree is. Usually, GBDT uses **shallow trees** to avoid overfitting and reduce computation.\n",
    "\n",
    "### Best Practices:\n",
    "- **Balance `n_estimators` and `learning_rate`**: Start with a lower `learning_rate` (like 0.01 or 0.1) and increase `n_estimators` until the model performs well without overfitting.\n",
    "- **Set a low `max_depth`**: Shallow trees (depth between 1 and 5) are common in GBDT to keep the model general and fast.\n",
    "- **Watch for overfitting**: A large number of trees can lead to overfitting if the learning rate and tree depth are not set carefully. You may need to use validation data to tune these parameters.\n",
    "\n",
    "GBDT is a highly effective algorithm when tuned correctly, making it a popular choice in competitions and industry applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
