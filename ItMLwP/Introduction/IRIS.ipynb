{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:03:56) [MSC v.1929 64 bit (AMD64)]\n",
      "pandas version: 2.2.2\n",
      "matplotlib version: 3.8.4\n",
      "NumPy version: 1.26.4\n",
      "SciPy version: 1.13.1\n",
      "IPython version: 8.24.0\n",
      "scikit-learn version: 1.4.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version: {}\".format(sys.version))\n",
    "import pandas as pd\n",
    "print(\"pandas version: {}\".format(pd.__version__))\n",
    "import matplotlib\n",
    "print(\"matplotlib version: {}\".format(matplotlib.__version__))\n",
    "import numpy as np\n",
    "print(\"NumPy version: {}\".format(np.__version__))\n",
    "import scipy as sp\n",
    "print(\"SciPy version: {}\".format(sp.__version__))\n",
    "import IPython\n",
    "print(\"IPython version: {}\".format(IPython.__version__))\n",
    "import sklearn\n",
    "print(\"scikit-learn version: {}\".format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we will use for this example is the Iris dataset, a classical dataset in machine learning and statistics. It is included in scikit-learn in the datasets module. We can load it by calling the load_iris function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iris object that is returned by load_iris is a Bunch object, which is very similar to a dictionary. It contains keys and values:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys id iris_dataset: \n",
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Keys id iris_dataset: \\n{}\".format(iris_dataset.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The value of the key DESCR is a short description of the dataset. We show the beginning of the description here (feel free to look up the rest yourself):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 150 (50 in each of three classes)\n",
      ":Number of Attributes: 4 numeric, predictive \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(iris_dataset['DESCR'][:193] + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of the key target_names is an array of strings, containing the species of flower that we want to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target names: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(\"Target names: {}\".format(iris_dataset['target_names']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of feature_names is a list of strings, giving the description of each feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: \n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature names: \\n{}\".format(iris_dataset['feature_names']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data itself is contained in the target and data fields. data contains the numeric measurements of sepal length, sepal width, petal length, and petal width in a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Type of data: <class 'numpy.ndarray'>\"}\n"
     ]
    }
   ],
   "source": [
    "print({\"Type of data: {}\".format(type(iris_dataset['data']))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows in the data array correspond to flowers, while the columns represent the four measurements that were taken for each flower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (150, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of data: {}\".format(iris_dataset['data'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the array contains measurements for 150 different flowers. Remember\n",
    "that the individual items are called samples in machine learning, and their properties\n",
    "are called features. The shape of the data array is the number of samples multiplied by\n",
    "the number of features. This is a convention in scikit-learn, and your data will\n",
    "always be assumed to be in this shape. Here are the feature values for the first five\n",
    "samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five colums of data :\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "print(\"First five colums of data :\\n {}\".format(iris_dataset['data'][:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this data, we can see that all of the first five flowers have a petal width of 0.2 cm\n",
    "and that the first flower has the longest sepal, at 5.1 cm.\n",
    "The target array contains the species of each of the flowers that were measured, also\n",
    "as a NumPy array:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of target: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of target: {}\".format(type(iris_dataset['target'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type of target: <class 'numpy.ndarray'>\n",
    "target is a one-dimensional array, with one entry per flower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of target: {}.format(iris_dataset['target'.shape])\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of target: {}.format(iris_dataset['target'.shape])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The species are encoded as integers from 0 to 2:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Target:\\n{}\".format(iris_dataset['target']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Success: Training and Testing Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
